{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56002e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rand\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad5e09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    \"\"\"\n",
    "    Implementation of SMO\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=1000, kernel_type='linear', C=1.0, eps=0.001):\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.eps = 0.001\n",
    "        self.kernel_type = kernel_type\n",
    "        self.kernel = {\n",
    "            'linear' : self.linear_kernel,\n",
    "            'quadratic' : self.quadratic_kernel\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def get_rand_number(self,low_lim,high_lim,i):\n",
    "        k = i\n",
    "        count = 0\n",
    "        while k == i and count<1000:\n",
    "            rand_numb = rand.randint(low_lim,high_lim)\n",
    "            count += 1\n",
    "        return(rand_numb)\n",
    "    \n",
    "    def L_H_calc(self,y_i,y_j,alpha_i,alpha_j,C):\n",
    "        if y_i==y_j:\n",
    "            L = max(0,alpha_i+alpha_j-C)\n",
    "            H = min(C,alpha_i+alpha_j)\n",
    "        else:\n",
    "            L = max(0,alpha_j-alpha_i)\n",
    "            H = min(C,C+alpha_j-alpha_i)\n",
    "        return(L,H)\n",
    "    \n",
    "    def kernel(self,x_i, x_j):\n",
    "        k = np.dot(x_i,x_j.T)\n",
    "        return(k)\n",
    "    \n",
    "    def func_val(self,x_i,alpha,y,x):\n",
    "        alpha_into_y = np.multiply(alpha,y)\n",
    "        w = np.dot(x.T,alpha_into_y)\n",
    "        b = np.mean(y - np.dot(w.T, x.T))\n",
    "        f_val = np.sign(np.dot(w.T,x_i) + b).astype(int)\n",
    "        return(f_val,w,b)\n",
    "    \n",
    "    def Err_val(self,f_x,y):\n",
    "        Err = f_x - y\n",
    "        return(Err)\n",
    "    \n",
    "    def linear_kernel(self,x_i, x_j):\n",
    "        lin_ker = np.dot(x_i,x_j.T)\n",
    "        return(lin_ker)\n",
    "    \n",
    "    def quadratic_kernel(self,x_i,x_j):\n",
    "        quad_ker = (np.dot(x_i,x_j.T))**2\n",
    "        return(quad_ker)\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "        Input Parameters\n",
    "        ================\n",
    "        X - Input data\n",
    "        y - Output data\n",
    "        \n",
    "        Output Parameters\n",
    "        ================\n",
    "        alpha \n",
    "        \"\"\"\n",
    "        # Initialization\n",
    "        n, d = X.shape[0], X.shape[1]\n",
    "        alpha = np.zeros((n))\n",
    "        kernel = self.kernel[self.kernel_type]\n",
    "        count = 0\n",
    "        \n",
    "        while count < self.max_iter:\n",
    "            count += 1\n",
    "            alpha_old = np.copy(alpha)\n",
    "            \n",
    "            for i in range(0,n):\n",
    "                j = self.get_rand_number(0,n-1,i) # get random number i~=j\n",
    "                \n",
    "                x_i,y_i = X[i,:], y[i]\n",
    "                x_j,y_j = X[j,:], y[j]\n",
    "                \n",
    "                eta = kernel(x_i, x_i) + kernel(x_j, x_j) - 2 * kernel(x_i, x_j)\n",
    "                if eta ==0:\n",
    "                    continue\n",
    "                \n",
    "                alpha_tmp_i,alpha_tmp_j = alpha[i], alpha[j]\n",
    "                \n",
    "                # Bounds for Lagrangian multipliers\n",
    "                L,H = self.L_H_calc(y_i,y_j,alpha_tmp_i,alpha_tmp_j,self.C)\n",
    "                \n",
    "                # Compute function and error\n",
    "                f_xi,wi,bi = self.func_val(x_i,alpha,y,X)\n",
    "            \n",
    "                Err_i = self.Err_val(f_xi,y_i)\n",
    "                f_xj,wj,bj = self.func_val(x_j,alpha,y,X)\n",
    "                Err_j = self.Err_val(f_xj,y_j)\n",
    "                \n",
    "                # Update values of alpha\n",
    "                alpha[j] = alpha_tmp_j + float(y_j * (Err_i - Err_j))/eta\n",
    "                alpha[j] = max(alpha[j], L)\n",
    "                alpha[j] = min(alpha[j], H)\n",
    "                \n",
    "                alpha[i] = alpha_tmp_i+(y[i]*y[j]*(alpha_tmp_j-alpha[j]))\n",
    "            \n",
    "            \n",
    "            alpha_diff = np.linalg.norm(alpha-alpha_old)\n",
    "            print('Iteration -',count)\n",
    "            print('alpha_difference -',alpha_diff)\n",
    "            \n",
    "            if alpha_diff < self.eps:\n",
    "                print(\"Model reached convergence criteria\")\n",
    "                break\n",
    "                \n",
    "            if count >= self.max_iter:\n",
    "                print(\"Max iterations reached\")\n",
    "                break\n",
    "            \n",
    "        # Identify support vectors\n",
    "        alpha_idx = np.where(alpha>0)\n",
    "        support_vectors = X[alpha_idx,:]\n",
    "        \n",
    "        f_x,w,b = self.func_val(X[1,:],alpha,y,X)\n",
    "        \n",
    "        return support_vectors,w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c66b3404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2) (700,)\n",
      "(array([0, 1]), array([355, 345], dtype=int64))\n",
      "(array([-1,  1]), array([355, 345], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data - Binary class\n",
    "X,y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_classes=2)\n",
    "\n",
    "# Test-Train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "\n",
    "zero_id = np.where(y_train==0)\n",
    "y_train[zero_id] = -1\n",
    "\n",
    "zero_id = np.where(y_test==0)\n",
    "y_test[zero_id] = -1\n",
    "\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e82dac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - 1\n",
      "alpha_difference - 7.037813126037299\n",
      "Iteration - 2\n",
      "alpha_difference - 4.801460706988365\n",
      "Iteration - 3\n",
      "alpha_difference - 3.0490879913757722\n",
      "Iteration - 4\n",
      "alpha_difference - 3.204743844441131\n",
      "Iteration - 5\n",
      "alpha_difference - 1.7692439765654142\n",
      "Iteration - 6\n",
      "alpha_difference - 0.718330477263191\n",
      "Iteration - 7\n",
      "alpha_difference - 1.075629700334484\n",
      "Iteration - 8\n",
      "alpha_difference - 0.24287641379866004\n",
      "Iteration - 9\n",
      "alpha_difference - 0.75602304321379\n",
      "Iteration - 10\n",
      "alpha_difference - 0.0956720107919485\n",
      "Iteration - 11\n",
      "alpha_difference - 0.18486077754446523\n",
      "Iteration - 12\n",
      "alpha_difference - 0.09091158197653922\n",
      "Iteration - 13\n",
      "alpha_difference - 2.830524433501838e-16\n",
      "Model reached convergence criteria\n"
     ]
    }
   ],
   "source": [
    "model = SVM(max_iter=100, kernel_type='linear', C=1.0, eps=0.01)\n",
    "support_vectors,w,b = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abe75ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.sign(np.dot(w.T, X_test.T) + b).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "104c8c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130,  18],\n",
       "       [ 13, 139]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34440d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132,  16],\n",
       "       [ 12, 140]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffaee4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
